"""Provides Steamship-compatible Cache for langchain (🦜️🔗) LLM calls.

This cache will persist across session, saving state to the workspace.
"""
