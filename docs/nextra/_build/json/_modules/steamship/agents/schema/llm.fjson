{"parents": [{"link": "../../../../", "title": "Module code"}], "title": "steamship.agents.schema.llm", "body": "<h1>Source code for steamship.agents.schema.llm</h1><div class=\"highlight\"><pre>\n<span></span><span class=\"kn\">from</span> <span class=\"nn\">abc</span> <span class=\"kn\">import</span> <span class=\"n\">ABC</span><span class=\"p\">,</span> <span class=\"n\">abstractmethod</span>\n<span class=\"kn\">from</span> <span class=\"nn\">typing</span> <span class=\"kn\">import</span> <span class=\"n\">List</span><span class=\"p\">,</span> <span class=\"n\">Optional</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">pydantic.main</span> <span class=\"kn\">import</span> <span class=\"n\">BaseModel</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">steamship</span> <span class=\"kn\">import</span> <span class=\"n\">Block</span>\n<span class=\"kn\">from</span> <span class=\"nn\">steamship.agents.schema.tool</span> <span class=\"kn\">import</span> <span class=\"n\">Tool</span>\n\n\n<div class=\"viewcode-block\" id=\"LLM\"><a class=\"viewcode-back\" href=\"../../../../../api/steamship.agents.schema/#steamship.agents.schema.llm.LLM\">[docs]</a><span class=\"k\">class</span> <span class=\"nc\">LLM</span><span class=\"p\">(</span><span class=\"n\">BaseModel</span><span class=\"p\">,</span> <span class=\"n\">ABC</span><span class=\"p\">):</span>\n<span class=\"w\">    </span><span class=\"sd\">&quot;&quot;&quot;LLM wraps large language model-based backends.</span>\n\n<span class=\"sd\">    They may be used with LLMAgents in Action selection, or for direct prompt completion.&quot;&quot;&quot;</span>\n\n<div class=\"viewcode-block\" id=\"LLM.complete\"><a class=\"viewcode-back\" href=\"../../../../../api/steamship.agents.schema/#steamship.agents.schema.llm.LLM.complete\">[docs]</a>    <span class=\"nd\">@abstractmethod</span>\n    <span class=\"k\">def</span> <span class=\"nf\">complete</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">prompt</span><span class=\"p\">:</span> <span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">stop</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">Block</span><span class=\"p\">]:</span>\n<span class=\"w\">        </span><span class=\"sd\">&quot;&quot;&quot;Completes the provided prompt, stopping when the stop sequeunce is found.&quot;&quot;&quot;</span>\n        <span class=\"k\">pass</span></div></div>\n\n\n<span class=\"c1\"># TODO(dougreid): should LLM and ConversationalLLM share a common parent?</span>\n<div class=\"viewcode-block\" id=\"ChatLLM\"><a class=\"viewcode-back\" href=\"../../../../../api/steamship.agents.schema/#steamship.agents.schema.llm.ChatLLM\">[docs]</a><span class=\"k\">class</span> <span class=\"nc\">ChatLLM</span><span class=\"p\">(</span><span class=\"n\">BaseModel</span><span class=\"p\">,</span> <span class=\"n\">ABC</span><span class=\"p\">):</span>\n<span class=\"w\">    </span><span class=\"sd\">&quot;&quot;&quot;ChatLLM wraps large language model-based backends that use a chat completion style interation.</span>\n\n<span class=\"sd\">    They may be used with Agents in Action selection, or for direct prompt completion.&quot;&quot;&quot;</span>\n\n<div class=\"viewcode-block\" id=\"ChatLLM.chat\"><a class=\"viewcode-back\" href=\"../../../../../api/steamship.agents.schema/#steamship.agents.schema.llm.ChatLLM.chat\">[docs]</a>    <span class=\"nd\">@abstractmethod</span>\n    <span class=\"k\">def</span> <span class=\"nf\">chat</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">messages</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">Block</span><span class=\"p\">],</span> <span class=\"n\">tools</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">Tool</span><span class=\"p\">]],</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">Block</span><span class=\"p\">]:</span>\n<span class=\"w\">        </span><span class=\"sd\">&quot;&quot;&quot;Sends the set of chat messages to the LLM, returning the next part of the conversation&quot;&quot;&quot;</span>\n        <span class=\"k\">pass</span></div></div>\n</pre></div>", "current_page_name": "_modules/steamship/agents/schema/llm", "sidebars": ["sidebar/brand.html", "sidebar/search.html", "sidebar/scroll-start.html", "sidebar/navigation.html", "sidebar/ethical-ads.html", "sidebar/scroll-end.html", "sidebar/variant-selector.html"], "customsidebar": null, "favicon_url": null, "logo_url": null, "alabaster_version": "0.7.12", "furo_version": "2023.03.27", "furo_navigation_tree": "", "furo_hide_toc": true, "furo_pygments": {"light": {"background": "#f8f8f8", "foreground": "black"}, "dark": {"background": "#272822", "foreground": "#f8f8f2"}}}